{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raymond Adams\n",
    "Intelligent Systems Final Project\n",
    "Joseph Puliparambil\n",
    "22 November 2019\n",
    "\n",
    "This code was adapted from a post from Arsh Panghal on 01 January 2019\n",
    "\n",
    "This is a sentiment analysis using deep RNN on twitter tweets, movie reviews, and book reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#All three are imported to help plot graphs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# this will be used for numpy arrays\n",
    "import numpy as np \n",
    "import csv\n",
    "import gc\n",
    "import os\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
    "\n",
    "# I am using TensorFlow's backend tensorflow-gpu. Thus I set the \"use_gpu\"=True. I decided to run this program on the gpu so that the program can process more functions faster. There is a lot of data here so using the gpu will increase the speed of creating the neural network.\n",
    "use_gpu=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I import the data through the given directories using pandas. The csv files both have one column. The column title in 'train.csv' is represented as 'tweet;sentiment'. Each row contains a tweet and sentiment value (o or 1). The data in these files contain tweets, movie reviews, book reviews and reviews from numerous shopping sites. When pandas reads the csv it seperates the text in the row by \";\". Thus the comments are under 'tweet' and the values representing negative (val=0) or posistive (val=1) comments are under 'sentiment'. These values of 0's and 1's are used to train the network on what negative and positive comments are based on the words inside the comment and the patterns that they are used in. The row in 'test.csv' do not contain the sentiment values. Instead the model will try to predict the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"question2/train.csv\",sep=';')\n",
    "test_data = pd.read_csv(\"question2/test.csv\",sep=';',quoting=csv.QUOTE_NONE)\n",
    "\n",
    "#this removes the users' username because this is not helpful in the sentiment analysis\n",
    "train_data['tweet'] = train_data['tweet'].apply(lambda x : ' '.join([w for w in x.split() if not w.startswith('@') ])  ) \n",
    "test_data['tweet'] = test_data['tweet'].apply(lambda x : ' '.join([w for w in x.split() if not w.startswith('@') ])  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a group of words that are referred to as \"stop words\" in Natural Language Processing. The most common \"stop words\" are \"is\", \"are\", and \"have\". These words should not be learned by the NLP because they have no connection with sentiment and will not contribute nor hinder the accuracy of the model. Thus, removing them will save processing time. This code also removes symbols which are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(train_data['tweet'].values) + list(test_data['tweet'].values)\n",
    "text = [i.lower() for i in text if i not in stopwords.words('english') and i not in ['.',',','/','@','\"','&amp','<br />','+/-','zzzzzzzzzzzzzzzzz',':-D',':D',':P',':)','!',';']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target variable (predictor variable)\n",
    "y = train_data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN requires the data to be in sequences. Keras Tokenizer() function converts the text in the train and test datasets to sequences. These sequences are then put through embedding matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = Tokenizer(lower = True, filters='')\n",
    "tkn.fit_on_texts(text)\n",
    "\n",
    "# takes the text and converts the sentence(s) into tokens. Tokens are basicaly strings of individual words or symbols.\n",
    "train_tkn = tkn.texts_to_sequences(train_data['tweet'])\n",
    "test_tkn = tkn.texts_to_sequences(test_data['tweet'])\n",
    "\n",
    "# this function 'pad_sequences()' converts a list of sequences, which  is just a list of integers, into a 2 dimensional Numpy array\n",
    "# the number of time_steps (max_len) is set to 50\n",
    "max_len = 50\n",
    "train_x = pad_sequences(train_tkn, maxlen = max_len)\n",
    "test_x = pad_sequences(test_tkn, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding is a the natural language processing technique that maps words to a n-dimensional space. It is used to teach computers how words are used and related. In other words it is the way to represent words to a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this variable hold the directory path to the word embeddings to be used\n",
    "path_to_embedding = \"word_embeddings\\glove_twitter.txt\"\n",
    "embedding_size = 200\n",
    "max_features = 30000\n",
    "\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "# creates a dictionary of the word embeddings. The words are grabbed from a text file.\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(path_to_embedding, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tkn.word_index\n",
    "# takes the smallest of the two inputs\n",
    "nb_words = min(max_features, len(word_index))\n",
    "# returns an array of zeros with shape (nb_words + 1, embedding_size)\n",
    "matrix_embedding = np.zeros((nb_words + 1, embedding_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    vector_embedding = embedding_index.get(word)\n",
    "    if vector_embedding is not None: matrix_embedding[i] = vector_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None\n",
    "\n",
    "\n",
    "def build_model1(learning_rate =0.0, decay_rate =0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
    "    \n",
    "    # declaring history as a global variable so that it can be called and plotted outside of build_model1()\n",
    "    global history \n",
    "    \n",
    "    file_path = \"best_model.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                                  save_best_only = True, mode = \"min\")\n",
    "    # this will stop training when a monitored quantity has stopped improving. Will happend if 3 epochs goes by with no improvement \n",
    "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
    "    \n",
    "    intake = Input(shape = (max_len,))\n",
    "    x = Embedding(30001, embedding_size, weights = [matrix_embedding], trainable = False)(intake)\n",
    "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
    "    \n",
    "    # connects 2 hidden layers that have opposite directions to the same output\n",
    "    # this allows the output layers to have information from past & future states\n",
    "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
    "    \n",
    "    # first convolution\n",
    "    # this is a 1 dimensional convolutional layer\n",
    "    x1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
    "    avg_pool1_gru = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_gru = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    # second convolution\n",
    "    x2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
    "    avg_pool3_gru = GlobalAveragePooling1D()(x2)\n",
    "    max_pool3_gru = GlobalMaxPooling1D()(x2)\n",
    "    \n",
    "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n",
    "    \n",
    "    # first convolution\n",
    "    x1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
    "    avg_pool1_lstm = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_lstm = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    # second convolution\n",
    "    x2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
    "    avg_pool3_lstm = GlobalAveragePooling1D()(x2)\n",
    "    max_pool3_lstm = GlobalMaxPooling1D()(x2)\n",
    "    \n",
    "    \n",
    "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool3_gru, max_pool3_gru,\n",
    "                    avg_pool1_lstm, max_pool1_lstm, avg_pool3_lstm, max_pool3_lstm])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
    "    x = Dense(1, activation = \"sigmoid\")(x)\n",
    "    model = Model(inputs = intake, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = learning_rate, decay = decay_rate), metrics = [\"accuracy\"])\n",
    "    history = model.fit(train_x, y, batch_size = 150, epochs = 10, validation_split=0.2, \n",
    "                        verbose = 1, callbacks = [check_point, early_stop])\n",
    "    model = load_model(file_path)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1121 21:15:29.743158 57752 deprecation_wrapper.py:119] From C:\\Users\\Radam\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1121 21:15:29.799812 57752 deprecation_wrapper.py:119] From C:\\Users\\Radam\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1121 21:15:29.818496 57752 deprecation_wrapper.py:119] From C:\\Users\\Radam\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1121 21:15:29.840512 57752 deprecation_wrapper.py:119] From C:\\Users\\Radam\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1121 21:15:29.841511 57752 deprecation_wrapper.py:119] From C:\\Users\\Radam\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1121 21:15:33.195326 57752 deprecation.py:506] From C:\\Users\\Radam\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1121 21:15:35.617263 57752 deprecation_wrapper.py:119] From C:\\Users\\Radam\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1121 21:15:35.627236 57752 deprecation.py:323] From C:\\Users\\Radam\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1026321 samples, validate on 256581 samples\n",
      "Epoch 1/10\n",
      "1026321/1026321 [==============================] - 631s 615us/step - loss: 0.5343 - acc: 0.7285 - val_loss: 0.4941 - val_acc: 0.7566\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49406, saving model to best_model.hdf5\n",
      "Epoch 2/10\n",
      "1026321/1026321 [==============================] - 668s 651us/step - loss: 0.5102 - acc: 0.7452 - val_loss: 0.4840 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49406 to 0.48404, saving model to best_model.hdf5\n",
      "Epoch 3/10\n",
      "1026321/1026321 [==============================] - 672s 654us/step - loss: 0.5026 - acc: 0.7503 - val_loss: 0.4787 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48404 to 0.47872, saving model to best_model.hdf5\n",
      "Epoch 4/10\n",
      "1026321/1026321 [==============================] - 667s 650us/step - loss: 0.4980 - acc: 0.7532 - val_loss: 0.4771 - val_acc: 0.7667\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.47872 to 0.47713, saving model to best_model.hdf5\n",
      "Epoch 5/10\n",
      "1026321/1026321 [==============================] - 668s 651us/step - loss: 0.4948 - acc: 0.7553 - val_loss: 0.4755 - val_acc: 0.7680\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.47713 to 0.47548, saving model to best_model.hdf5\n",
      "Epoch 6/10\n",
      "1026321/1026321 [==============================] - 666s 649us/step - loss: 0.4927 - acc: 0.7564 - val_loss: 0.4742 - val_acc: 0.7688\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47548 to 0.47420, saving model to best_model.hdf5\n",
      "Epoch 7/10\n",
      "1026321/1026321 [==============================] - 669s 652us/step - loss: 0.4907 - acc: 0.7574 - val_loss: 0.4728 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47420 to 0.47280, saving model to best_model.hdf5\n",
      "Epoch 8/10\n",
      "1026321/1026321 [==============================] - 670s 652us/step - loss: 0.4891 - acc: 0.7587 - val_loss: 0.4724 - val_acc: 0.7707\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47280 to 0.47239, saving model to best_model.hdf5\n",
      "Epoch 9/10\n",
      "1026321/1026321 [==============================] - 667s 650us/step - loss: 0.4872 - acc: 0.7598 - val_loss: 0.4722 - val_acc: 0.7704\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.47239 to 0.47222, saving model to best_model.hdf5\n",
      "Epoch 10/10\n",
      "1026321/1026321 [==============================] - 670s 653us/step - loss: 0.4862 - acc: 0.7605 - val_loss: 0.4712 - val_acc: 0.7711\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.47222 to 0.47121, saving model to best_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate' is the rate at which the model updates the weights in the units during back-propagation\n",
    "model = build_model1(learning_rate = 0.01, decay_rate = 0.001, units = 150, spatial_dr = 0.5, kernel_size1=4, kernel_size2=4, dense_units=64, dr=0.2, conv_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
